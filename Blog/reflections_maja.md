# Reflections - Maja
The things I worked on in the projects are mainly the NPC and everything that is to do with it. In the AR I did not have a specific part that I focused on but I looked into how to make text appear after the modal was placed.  

Working on the AR project was the first time I have worked on an XR project so there was a bit of a learning curve. I got the feeling that the communication between the members was not as good as it should have been. I felt as if it was not clear what part was being worked on. But I ended up working on some UI that would show text only when the modal was placed. I also worked on other things for this but this is where we were not clear enough with who was doing what as the others made something similar to what I was also making so I discarded my version to avoid duplication. This was worse in the start and became better the further we were in the project. We all worked together to combine and finish the project.

The VR project was easier to distribute the tasks to the different members. My main focus was on making the NPC, while I also kept an overview of this project and its progress. The NPCs are represented as a capsule with a box for eyes while the NPCs functions and behaviours were implemented in the scripts. One key functionality was player detection. The “NPCVision” script defines the field in which the player can be spotted while preventing vision through walls or doors. This is achieved by specifying which layers block the NPC’s vision when tracking the XR origin. Vision links to the “NPCController”, which manages the NPC’s state. Keeping these separate improves modularity and clarity.
The states the NPC can be in are Patrol, Chase and Wait. The Patrol state is the default, where the NPC moves between points defined by empty GameObjects, allowing flexible routes for different map layouts. The Chase state does as you would expect, chase the player if spotted. The pathfinding uses a NavMash that is baked without the doors layer so the NPCs can navigate and chase across the whole map. The NPC chases the player but the chasing can be stopped if the player moves out of a pre-determent distance from the NPC or if a door closes after the player, the NPC then enters the Wait state. If the player is caught the player will teleport back to a respawn point. 
Initially, the teleport used “PlayerStartPosition”, but this is deprecated. The current implementation uses the “PlayerTeleportWithFade” script, which moves the player to the respawn point and animates an Image with coroutine to fade from 0% to 100% and back. The Image follows the player by being on the main camera instead of with the other UI objects. The fade was done to minimize motion sickness for the player. The teleport also resets the NPCs, so they go back to their patrol routes. The Wait state allows the NPC to pause before returning to patrol or chasing again, smoothing the transition.

One thing I should do if this was a bigger project was make the NPCs into prefabs. This was not done because of the size of the project. However if it became just slightly bigger then having them be prefabs would be optimal. Making them into prefabs is easy and there would be two different NPCs. The main difference is in the amount of vision the standstill NPC and the patrolling NPCs have. This was done because of how the patrol points works, as they do not have a rotation, so the standstill NPC would look the wrong way if it chased once. The current solution expands the view of stationary NPCs, which works but is not a scalable solution.

Throughout the project, my focus has not been specific to the XR systems, but I applied XR concepts where it was relevant, such as tracking the player’s headset using raycasts for line-of-sight detection. This allows the player to maintain the full 6 DOF while still supporting a realistic NPC vision. While the XR Interaction Toolkit includes a built-in teleport functionality, it was more practical to implement teleport with scripts for this project, since the player is not allowed to teleport freely around the map. The built-in system is designed for general locomotion and would require significant setup and adjustments to restrict movement to only teleport when the NPC collides with the player. Using scripts to teleport allows for control over when and where the player moves, ensures the NPCs could be properly reset, and enables a smooth fade effect to minimize motion sickness. 

In conclusion, my main focus was on the VR project, where I had an overview of the project and implemented the NPC and its functionality. I made sure that the gameplay mechanics related to the NPC, including player detection, NPC states, and teleportation with fade, were working and could integrate easily with the rest of the project.
